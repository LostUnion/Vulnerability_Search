import os
import re
import sys
from httpx import AsyncClient
import shutil
import logging
import asyncio
import argparse
from nmap import nmap
from concurrent.futures import ThreadPoolExecutor

client = AsyncClient()

logger = logging.getLogger('scanner_logger')
logger.setLevel(logging.INFO)
form = logging.Formatter('%(actime)s - %(levelname)s - %(message)s')
log_handler = logging.StreamHandler()
log_handler.setFormatter(form)
logger.addHandler(log_handler)

executor = ThreadPoolExecutor(max_workers=10)
path_list = []

async def collect_subdomains(domain: str):
    local_subdomains = set()
    try:
        res = await client.get(url='https://crt.sh', params={"q": domain, "output": "json"}, timeout=10)
    except Exception as err:
        logger.error(f'There is no way to get data from crt.sh: {err}')
        sys.exit(1)

    data = res.json()

    if not data:
        logger.error(f'Subdomains for the domain {domain} not found')
        return []
    
    for rec in data:
        names = rec["name_value"].split('\n')
        _ = [local_subdomains.add(re.sub(r"^\*\.|www\.", "", name)) for name in names]
    
    logger.info(f'Subdomains: {list(local_subdomains)}')
    return list(local_subdomains)


async def async_scan_ports(domain: str):
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(executor, scan_ports, domain)

def scan_ports(domain: str):
    nm = nmap.PortScanner()
    _ = nm.scan(domain, arguments='-sV --script vulners', sudo=True)
    for host in nm.all_hosts():
        for proto in nm[host].all_protocols():
            port_list = nm[host][proto].keys()
            for port in port_list:
                port_info = nm[host][proto][port]

                logger.info(
                    f"""
                        ===========
                        URL: {domain}
                        Host: {host}
                        Port: {port}
                        Status: {port_info['state']}
                        Name: {port_info['name']}
                        Service: {port_info['product']}
                        Version: {port_info['version']}
                        Potential vulnerabilities: {port_info.get('script', {}).get('vulners')}
                    """.strip()
                )

def check_empty_floder(path: str):
    try:
        if not os.listdir(path):
            shutil.rmtree(path)
            return True
    except Exception as err:
        logger.error(f"Не удалось найти папку '{path}': {err}")

async def run_sqlmap(target_url: str):
    path = os.path.join(os.getcwd(), 'sqlmap_result', target_url)
    os.makedirs(path, exist_ok=True)
    command = [
        'sqlmap', '-u', f"{target_url if 'https://' in target_url else f'https://{target_url}'}",
        '--crawl=1', '--batch', '--random-agent',
        '--output-dir', path
    ]

    await asyncio.create_subprocess_exec(*command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
    path_list.append(path)

async def main(domain: str):
    subdomains = await collect_subdomains(domain=domain)
    tasks = [asyncio.create_task(run_sqlmap(subdomain)) for subdomain in subdomains] + [asyncio.create_task(async_scan_ports(subdomain)) for subdomain in subdomains]
    for task in asyncio.as_completed(tasks):
        await task
    [check_empty_floder(path) for path in path_list]
    logger.info("The scan results are in the folder '/sqlmap_result'")
    

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Search')
    parser.add_argument('-d', '--domain', type=str, help='Domain address')
    args = parser.parse_args()
    asyncio.run(main(args.domain))